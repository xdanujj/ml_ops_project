name: Databricks CI/CD Pipeline

on:
  push:
    branches: [ main ]     # pipeline runs automatically whenever code is pushed to 'main'

jobs:
  build-train-deploy:
    runs-on: ubuntu-latest

    steps:
      # Step 1Ô∏è‚É£: Checkout your repository code
      - name: Checkout repository
        uses: actions/checkout@v4

      # Step 2Ô∏è‚É£: Set up Python environment
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      # Step 3Ô∏è‚É£: Install dependencies
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install pytest databricks-cli

      # Step 4Ô∏è‚É£: Run simple tests (to ensure repo integrity)
      - name: Run tests
        run: pytest tests/

      # Step 5Ô∏è‚É£: Trigger Databricks Job (Model Training on Cloud)
      - name: Trigger Databricks Training Job
        env:
          DATABRICKS_HOST: ${{ secrets.DATABRICKS_HOST }}
          DATABRICKS_TOKEN: ${{ secrets.DATABRICKS_TOKEN }}
          DATABRICKS_JOB_ID: ${{ secrets.DATABRICKS_JOB_ID }}
        run: |
          echo "üöÄ Starting Databricks job..."
          databricks jobs run-now --job-id $DATABRICKS_JOB_ID
          echo "‚úÖ Databricks job triggered successfully!"

      # Step 6Ô∏è‚É£ (Optional): Build and Push Docker Image
      - name: Build and Push Docker Image
        if: success()
        env:
          DOCKER_USER: ${{ secrets.DOCKER_USER }}
          DOCKER_PASS: ${{ secrets.DOCKER_PASS }}
        run: |
          echo "üê≥ Building Docker image..."
          echo $DOCKER_PASS | docker login -u $DOCKER_USER --password-stdin
          docker build -t $DOCKER_USER/crop-rec-model:latest .
          docker push $DOCKER_USER/crop-rec-model:latest
          echo "‚úÖ Docker image pushed successfully!"
